{
  "model": "qwen3",
  "notes": "汇总公开报道与社区跑分，包含官方 blog/arXiv、代码仓、媒体报道与社区复现（注明来源类型）。",
  "benchmarks": [
    {
      "name": "MMLU / MMLU-Pro",
      "metric": "accuracy",
      "value": "~82-84 for large variants (reported)",
      "source_type": "community / paper / blog",
      "source": "Reddit community run (user report) and arXiv/blog summaries",
      "link": "https://www.reddit.com/r/LocalLLaMA/comments/1kh6kh3/qwen3_mmlupro_computer_science_llm_benchmark/"
    },
    {
      "name": "Various benchmarks (math/coding/reasoning)",
      "metric": "mixed (accuracy/Pass@1/other)",
      "value": "Competitive with top-tier models per official blog and press coverage (see notes)",
      "source_type": "official blog / press",
      "source": "Qwen team blog and press articles",
      "link": "https://qwenlm.github.io/blog/qwen3/"
    },
    {
      "name": "Repo / artifacts",
      "metric": "n/a",
      "value": "model cards, releases and benchmark config available",
      "source_type": "code repo",
      "source": "GitHub QwenLM/Qwen3",
      "link": "https://github.com/QwenLM/Qwen3"
    }
  ]
}
