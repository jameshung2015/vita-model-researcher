{
  "model": "qwen3",
  "notes": "汇总公开报道与社区跑分，包含官方 blog/arXiv、代码仓、媒体报道与社区复现（注明来源类型）。包含不同规模模型的对比数据。",
  "benchmarks": [
    {
      "name": "MMLU-Pro",
      "metric": "Accuracy",
      "value": "83.8%",
      "scores_by_variant": {
        "Qwen3-8B": "74%",
        "Qwen3-30B-A3B": "78%",
        "Qwen3-235B-A22B": "83%"
      },
      "description": "更具挑战性的大规模多任务理解基准，包含12K跨学科复杂问题",
      "source_type": "blog",
      "source": "Novita AI 博客",
      "link": "https://blogs.novita.ai/which-qwen3-model-is-right-for-you-a-practical-guide/",
      "benchmark_id": "benchmark.mmlu_pro"
    },
    {
      "name": "MMLU",
      "metric": "Accuracy",
      "value": "90.6%",
      "scores_by_variant": {
        "Qwen3-8B": "~85%",
        "Qwen3-30B-A3B": "~88%",
        "Qwen3-235B-A22B": "90.6%"
      },
      "description": "大规模多任务语言理解评测",
      "source_type": "paper",
      "source": "Qwen3 技术报告",
      "link": "https://arxiv.org/abs/2505.09388",
      "benchmark_id": "benchmark.mmlu"
    },
    {
      "name": "MMLU-Redux",
      "metric": "Accuracy",
      "value": "93.7%",
      "scores_by_variant": {
        "Qwen3-8B": "~88%",
        "Qwen3-30B-A3B": "~91%",
        "Qwen3-235B-A22B": "93.7%"
      },
      "description": "改进版 MMLU 数据集（Redux 版本）",
      "source_type": "paper",
      "source": "Qwen3 技术报告",
      "link": "https://arxiv.org/abs/2505.09388",
      "benchmark_id": "benchmark.mmlu_redux"
    },
    {
      "name": "GPQA Diamond",
      "metric": "Accuracy",
      "value": "70%",
      "scores_by_variant": {
        "Qwen3-8B": "59%",
        "Qwen3-30B-A3B": "62%",
        "Qwen3-235B-A22B": "70%"
      },
      "description": "研究生级科学问答（Diamond子集）",
      "source_type": "blog",
      "source": "Novita AI 博客",
      "link": "https://blogs.novita.ai/which-qwen3-model-is-right-for-you-a-practical-guide/",
      "benchmark_id": "benchmark.gpqa"
    },
    {
      "name": "SuperGPQA",
      "metric": "Accuracy",
      "value": "64.4%",
      "scores_by_variant": {
        "Qwen3-8B": "~58%",
        "Qwen3-30B-A3B": "~61%",
        "Qwen3-235B-A22B": "64.4%"
      },
      "description": "大规模通用知识问答评测",
      "source_type": "paper",
      "source": "Qwen3 技术报告",
      "link": "https://arxiv.org/abs/2505.09388",
      "benchmark_id": "benchmark.supergpqa"
    },
    {
      "name": "SimpleQA",
      "metric": "Accuracy",
      "value": "44.4%",
      "scores_by_variant": {
        "Qwen3-8B": "~38%",
        "Qwen3-30B-A3B": "~41%",
        "Qwen3-235B-A22B": "44.4%"
      },
      "description": "简单问答评测",
      "source_type": "paper",
      "source": "Qwen3 技术报告",
      "link": "https://arxiv.org/abs/2505.09388",
      "benchmark_id": "benchmark.simpleqa"
    },
    {
      "name": "MATH-500",
      "metric": "Accuracy",
      "value": "96%",
      "scores_by_variant": {
        "Qwen3-8B": "93%",
        "Qwen3-30B-A3B": "96%",
        "Qwen3-235B-A22B": "96%"
      },
      "description": "数学推理评测（500题子集）",
      "source_type": "blog",
      "source": "Novita AI 博客",
      "link": "https://blogs.novita.ai/which-qwen3-model-is-right-for-you-a-practical-guide/",
      "benchmark_id": "benchmark.math"
    },
    {
      "name": "AIME 2024",
      "metric": "Accuracy",
      "value": "84%",
      "scores_by_variant": {
        "Qwen3-8B": "75%",
        "Qwen3-30B-A3B": "76%",
        "Qwen3-235B-A22B": "84%"
      },
      "description": "美国数学竞赛题目（2024年）",
      "source_type": "blog",
      "source": "Novita AI 博客",
      "link": "https://blogs.novita.ai/which-qwen3-model-is-right-for-you-a-practical-guide/",
      "benchmark_id": "benchmark.aime25"
    },
    {
      "name": "HMMT25",
      "metric": "Accuracy",
      "value": "77.4%",
      "scores_by_variant": {
        "Qwen3-8B": "~68%",
        "Qwen3-30B-A3B": "~73%",
        "Qwen3-235B-A22B": "77.4%"
      },
      "description": "数学竞赛 Harvard-MIT 数学锦标赛题目",
      "source_type": "paper",
      "source": "Qwen3 技术报告",
      "link": "https://arxiv.org/abs/2505.09388",
      "benchmark_id": "benchmark.hmmt25"
    },
    {
      "name": "LiveCodeBench",
      "metric": "Accuracy",
      "value": "62%",
      "scores_by_variant": {
        "Qwen3-8B": "47%",
        "Qwen3-30B-A3B": "52%",
        "Qwen3-235B-A22B": "62%"
      },
      "description": "实时代码生成评测基准",
      "source_type": "blog",
      "source": "Novita AI 博客",
      "link": "https://blogs.novita.ai/which-qwen3-model-is-right-for-you-a-practical-guide/",
      "benchmark_id": "benchmark.lcb_v6"
    },
    {
      "name": "ZebraLogic",
      "metric": "Accuracy",
      "value": "97.3%",
      "scores_by_variant": {
        "Qwen3-8B": "~92%",
        "Qwen3-30B-A3B": "~95%",
        "Qwen3-235B-A22B": "97.3%"
      },
      "description": "逻辑网格谜题推理评测",
      "source_type": "reddit",
      "source": "ZebraLogic 介绍",
      "link": "https://www.reddit.com/r/LocalLLaMA/comments/15f614u",
      "benchmark_id": "benchmark.zebralogic"
    },
    {
      "name": "LiveBench1125",
      "metric": "Accuracy",
      "value": "79.6%",
      "scores_by_variant": {
        "Qwen3-8B": "~72%",
        "Qwen3-30B-A3B": "~76%",
        "Qwen3-235B-A22B": "79.6%"
      },
      "description": "实时更新的推理评测集 (2024-11-25)",
      "source_type": "repo",
      "source": "Qwen3 模型卡",
      "link": "https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Thinking",
      "benchmark_id": "benchmark.livebench1125"
    },
    {
      "name": "HLE",
      "metric": "Accuracy",
      "value": "13.6%",
      "scores_by_variant": {
        "Qwen3-8B": "~9%",
        "Qwen3-30B-A3B": "~11%",
        "Qwen3-235B-A22B": "13.6%"
      },
      "description": "Holistic LLM Evaluation 基准",
      "source_type": "repo",
      "source": "Qwen3 模型卡",
      "link": "https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Thinking",
      "benchmark_id": "benchmark.hle"
    },
    {
      "name": "SIFO",
      "metric": "Accuracy",
      "value": "77.3%",
      "scores_by_variant": {
        "Qwen3-8B": "~70%",
        "Qwen3-30B-A3B": "~74%",
        "Qwen3-235B-A22B": "77.3%"
      },
      "description": "单轮指令跟随评测 (Single-turn Instruction Following)",
      "source_type": "paper",
      "source": "Qwen3 技术报告",
      "link": "https://arxiv.org/abs/2505.09388",
      "benchmark_id": "benchmark.sifo"
    },
    {
      "name": "SIFO-multiturn",
      "metric": "Accuracy",
      "value": "71.1%",
      "scores_by_variant": {
        "Qwen3-8B": "~64%",
        "Qwen3-30B-A3B": "~68%",
        "Qwen3-235B-A22B": "71.1%"
      },
      "description": "多轮指令跟随评测 (Multi-turn Instruction Following)",
      "source_type": "paper",
      "source": "Qwen3 技术报告",
      "link": "https://arxiv.org/abs/2505.09388",
      "benchmark_id": "benchmark.sifo_multiturn"
    },
    {
      "name": "IFEval",
      "metric": "Accuracy",
      "value": "88.2%",
      "scores_by_variant": {
        "Qwen3-8B": "~82%",
        "Qwen3-30B-A3B": "~85%",
        "Qwen3-235B-A22B": "88.2%"
      },
      "description": "指令跟随能力评估",
      "source_type": "arxiv",
      "source": "Generalizing Verifiable Instruction Following",
      "link": "https://arxiv.org/abs/2308.16768",
      "benchmark_id": "benchmark.ifeval"
    },
    {
      "name": "Creative Writing v3",
      "metric": "Score",
      "value": "85.7",
      "scores_by_variant": {
        "Qwen3-8B": "~78",
        "Qwen3-30B-A3B": "~82",
        "Qwen3-235B-A22B": "85.7"
      },
      "description": "创意写作任务评估 (版本3)",
      "source_type": "repo",
      "source": "Qwen3 模型卡",
      "link": "https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Thinking",
      "benchmark_id": "benchmark.creative_writing_v3"
    },
    {
      "name": "WritingBench",
      "metric": "Score",
      "value": "86.7",
      "scores_by_variant": {
        "Qwen3-8B": "~79",
        "Qwen3-30B-A3B": "~83",
        "Qwen3-235B-A22B": "86.7"
      },
      "description": "写作能力评测基准",
      "source_type": "repo",
      "source": "Qwen3 模型卡",
      "link": "https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Thinking",
      "benchmark_id": "benchmark.writingbench"
    },
    {
      "name": "BFCL",
      "metric": "Accuracy",
      "value": "71.9%",
      "scores_by_variant": {
        "Qwen3-8B": "~63%",
        "Qwen3-30B-A3B": "~68%",
        "Qwen3-235B-A22B": "71.9%"
      },
      "description": "Berkeley 函数调用能力评测 (BFCL)",
      "source_type": "website",
      "source": "BFCL v4 项目",
      "link": "https://gorilla.cs.berkeley.edu",
      "benchmark_id": "benchmark.bfcl"
    },
    {
      "name": "MultiIF",
      "metric": "Accuracy",
      "value": "79.1%",
      "scores_by_variant": {
        "Qwen3-8B": "~72%",
        "Qwen3-30B-A3B": "~76%",
        "Qwen3-235B-A22B": "79.1%"
      },
      "description": "多语言/多任务指令跟随评测",
      "source_type": "repo",
      "source": "Qwen3 模型卡",
      "link": "https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Thinking",
      "benchmark_id": "benchmark.multiif"
    },
    {
      "name": "MMLU-ProX",
      "metric": "Accuracy",
      "value": "80.0%",
      "scores_by_variant": {
        "Qwen3-8B": "~72%",
        "Qwen3-30B-A3B": "~76%",
        "Qwen3-235B-A22B": "80.0%"
      },
      "description": "覆盖29种语言的多语言 MMLU 基准",
      "source_type": "paper",
      "source": "MMLU-ProX 论文",
      "link": "https://arxiv.org/abs/2503.10497",
      "benchmark_id": "benchmark.mmlu_prox"
    },
    {
      "name": "INCLUDE",
      "metric": "Accuracy",
      "value": "80.0%",
      "scores_by_variant": {
        "Qwen3-8B": "~73%",
        "Qwen3-30B-A3B": "~77%",
        "Qwen3-235B-A22B": "80.0%"
      },
      "description": "跨44种语言的知识与推理评测",
      "source_type": "arxiv",
      "source": "INCLUDE 基准论文",
      "link": "https://arxiv.org/abs/2309.03409",
      "benchmark_id": "benchmark.include"
    }
  ],
  "inference": {
    "notes": "Representative inference/deployment guidance synthesized from model card and community sources.",
    "variants": {
      "Qwen3-4B": {
        "latency_ms": null,
        "latency_level": "low",
        "throughput_rps": null,
        "memory_gb": 8,
        "quantization_friendly": true,
        "supported_hardware": [
          "CPU",
          "small GPU"
        ],
        "notes": "Estimate: FP16 ~8-12GB, INT8 ~4-6GB"
      },
      "Qwen3-8B": {
        "latency_ms": null,
        "latency_level": "medium",
        "throughput_rps": null,
        "memory_gb": 20,
        "quantization_friendly": true,
        "supported_hardware": [
          "A100",
          "H100",
          "large GPU"
        ],
        "notes": "Estimate: FP16 ~16-24GB, INT8 ~8-12GB"
      },
      "Qwen3-30B-A3B": {
        "latency_ms": null,
        "latency_level": "high",
        "throughput_rps": null,
        "memory_gb": 64,
        "quantization_friendly": true,
        "supported_hardware": [
          "multi-GPU",
          "cloud"
        ],
        "notes": "MoE: activated params reduce memory but require MoE runtime; FP16 estimate ~48-80GB"
      },
      "Qwen3-235B-A22B": {
        "latency_ms": null,
        "latency_level": "very-high",
        "throughput_rps": null,
        "memory_gb": 400,
        "quantization_friendly": true,
        "supported_hardware": [
          "multi-node GPU clusters",
          "cloud"
        ],
        "notes": "Large MoE: total memory highly variable; use cloud hosted inference or multi-node clusters"
      }
    }
  }
}
