{
  "id": "benchmark.zerobench",
  "name": "ZeroBench",
  "description": "Visual reasoning benchmark featuring zero-shot puzzles and logic problems without prior training examples.",
  "source": "OpenCompass, 2024",
  "datasets": [
    {
      "name": "ZeroBench",
      "link": "https://huggingface.co/datasets/OpenCompass/ZeroBench",
      "license": "Refer to dataset repository"
    }
  ],
  "metrics": [
    {
      "name": "accuracy",
      "definition": "Puzzle success rate under zero-shot conditions",
      "calculation": "correct / total"
    }
  ],
  "test_method": "Present each puzzle with instructions; models must infer rules without examples. Evaluate using answer key.",
  "example_scores": {
    "Qwen3-VL-235B-A22B": "29.9% (Qwen3-VL technical report)",
    "GPT-4V": "26.4% (OpenCompass evaluation)"
  },
  "notes": "Document prompt strategy and whether self-consistency sampling was used to mitigate randomness."
}