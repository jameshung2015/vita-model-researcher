{
  "id": "benchmark.alpacaeval",
  "name": "AlpacaEval",
  "description": "自动化的指令跟随语言模型评估工具，专门设计用于快速、便宜且高度与人类评估相关的模型评测。AlpacaEval 2.0版本与ChatBot Arena的相关性达到0.98。",
  "source": "Stanford Tatsu Lab, 2023",
  "provider": "Stanford University",
  "category": "instruction_following",
  "datasets": [
    {
      "name": "AlpacaEval数据集",
      "description": "805个指令跟随评估样例，简化自AlpacaFarm评估集",
      "link": "https://huggingface.co/datasets/tatsu-lab/alpaca_eval",
      "license": "Apache-2.0"
    },
    {
      "name": "人类偏好数据",
      "description": "20K人类偏好标注，2.5K交叉标注",
      "link": "https://huggingface.co/datasets/tatsu-lab/alpaca_eval",
      "license": "Apache-2.0"
    }
  ],
  "evaluation_dimensions": [
    "指令跟随能力",
    "回答质量",
    "有用性",
    "准确性",
    "语言流畅性"
  ],
  "metrics": [
    {"name": "胜率", "definition": "模型输出相对于参考模型的胜率", "calculation": "wins / (wins + losses)"},
    {"name": "长度控制胜率", "definition": "控制长度偏差后的胜率", "calculation": "length_controlled_win_rate"},
    {"name": "标准误差", "definition": "胜率的统计标准误差", "calculation": "standard_error_of_mean"},
    {"name": "样本数", "definition": "用于计算胜率的样本总数", "calculation": "total_comparisons"}
  ],
  "test_method": "使用强大的LLM（如GPT-4）作为自动评估器，比较目标模型与参考模型的输出质量。支持缓存、批处理和输出随机化。默认使用weighted_alpaca_eval_gpt4_turbo评估器。",
  "technical_features": [
    "自动评估器",
    "长度偏差控制",
    "结果缓存",
    "批量处理",
    "输出随机化",
    "多评估器支持"
  ],
  "supported_evaluators": [
    "weighted_alpaca_eval_gpt4_turbo (推荐)",
    "alpaca_eval_gpt4",
    "alpaca_eval_cot_gpt4_turbo_fn",
    "claude",
    "其他自定义评估器"
  ],
  "example_scores": {
    "gpt4": "95.3% 胜率",
    "claude": "88.4% 胜率", 
    "chatgpt": "86.1% 胜率",
    "guanaco-65b": "71.8% 胜率",
    "text_davinci_003": "50.0% 胜率 (基准)"
  },
  "cost_and_time": {
    "cost": "<$10 OpenAI credits",
    "time": "<3 minutes",
    "correlation": "0.98 with ChatBot Arena"
  },
  "installation": "pip install alpaca-eval",
  "usage": "alpaca_eval --model_outputs outputs.json --annotators_config weighted_alpaca_eval_gpt4_turbo",
  "limitations": [
    "指令可能不代表真实使用",
    "自动评估器存在偏差",
    "缺少安全性评估",
    "偏好长输出和列表格式"
  ],
  "website": "https://tatsu-lab.github.io/alpaca_eval/",
  "github": "https://github.com/tatsu-lab/alpaca_eval", 
  "notes": "快速且成本低廉的指令跟随能力评估工具，与人类偏好高度相关。长度控制版本有效减少了长度偏差问题。适合模型开发阶段的快速评估。"
}