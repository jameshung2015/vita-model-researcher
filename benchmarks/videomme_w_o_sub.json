{
  "id": "benchmark.videomme_w_o_sub",
  "name": "VideoMME (no subtitles)",
  "description": "Video question answering benchmark evaluating multimodal understanding without subtitle transcripts.",
  "source": "Fu et al., 2024",
  "datasets": [
    {
      "name": "VideoMME",
      "link": "https://github.com/TencentARC/VideoMME",
      "license": "Research use"
    }
  ],
  "metrics": [
    {
      "name": "accuracy",
      "definition": "Multiple-choice accuracy on VideoMME with subtitles removed",
      "calculation": "correct / total"
    }
  ],
  "test_method": "Sample frames/clips from each video and present along with the question. Evaluate using official scoring scripts.",
  "example_scores": {
    "Kimi K2.5": "87.4% (Kimi report)",
    "Qwen3-VL-235B-A22B": "79.2% (Qwen3-VL technical report)",
    "GPT-4V": "72.5% (VideoMME leaderboard)"
  },
  "notes": "Document frame sampling rate and clip length. Ensure audio tracks are excluded in the no-subtitles setting."
}