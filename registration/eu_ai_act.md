# 欧盟 AI Act — 要点摘要（参考资料）

来源：European Commission / AI Act final text（2024）

关键信息：

- 风险分层：禁止类、不可接受/高风险/有限风险/最小风险。高风险AI系统（high-risk）在上架前需满足严格的合规要求。
- 高风险义务：风险管理体系、数据质量、技术文档（技术档案）、记录与日志、透明度、人工监督、性能与安全验证、基础模型与组件的合规（对通用目的模型也有特定义务）。
- 登记/数据库：法规要求建立EU层面的登记或数据库（对 Annex III 列明的高风险系统及特定类别），以便监管与追溯。
- 认证与合格评定：对某些高风险系统，需要通过合格评定/第三方检测（或依赖内部控制并保留证据）。
- 罚则：违反规定可能面临显著罚款和市场禁入等行政处罚。

对产品/模型的影响（建议）：

- 在设计阶段完成风险分类（是否落入 Annex II/III 的范围）。
- 准备技术档案（训练数据说明、模型评估报告、风险评估、监测计划）。
- 若提供给欧盟市场，准备在内部/外部进行的合格评定并保留证据与记录。

权威链接：
- https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai
- https://artificialintelligenceact.eu/the-act/
- https://artificialintelligenceact.eu/ai-act-explorer/
