# AGI-Eval 评测框架研究

## 概述
AGI-Eval是一个以人为中心的基准测试，专门设计用于评估基础模型在人类标准化考试中的表现，如大学入学考试、法学院入学考试、数学竞赛和律师资格考试等。

## 核心理念
- **人类中心**：基于真实的人类标准化考试
- **AGI导向**：评估模型向通用人工智能发展的能力
- **权威性**：使用官方考试题目确保评估的权威性
- **综合性**：覆盖多个学科和能力维度

## 评测内容
### 1. 考试类型
- **SAT**：美国大学入学考试
- **LSAT**：法学院入学考试
- **数学竞赛**：各类数学竞赛题目
- **律师资格考试**：法律专业资格认证
- **中国高考**：中国大学入学考试
- **其他标准化考试**

### 2. 能力维度
- **理解能力**：文本理解和语言掌握
- **知识掌握**：各学科知识的掌握程度
- **推理能力**：逻辑推理和批判性思维
- **计算能力**：数学计算和问题解决

## 评测结果
### GPT-4表现
- SAT数学：95%准确率
- 中国高考英语：92.5%准确率
- 在多项考试中超越平均人类表现

### 模型局限性
- 复杂推理任务表现不足
- 特定领域知识有限
- 需要进一步提升的能力领域

## 技术特点
1. **真实场景**：使用真实考试环境和题目
2. **标准化**：统一的评测标准和流程
3. **可比性**：可与人类表现直接对比
4. **多维度**：从多个角度评估模型能力

## 数据集构成
- 多个国家和地区的标准化考试
- 不同学科和难度级别
- 历年真题和模拟题
- 详细的评分标准

## 应用价值
1. **能力评估**：客观评估模型的综合能力
2. **发展指导**：指明模型改进方向
3. **基准对比**：提供统一的对比标准
4. **进展跟踪**：追踪AGI发展进程

## 获取方式
- 论文: https://arxiv.org/abs/2304.06364
- GitHub: https://github.com/ruixiangcui/AGIEval
- 数据和代码已开源发布